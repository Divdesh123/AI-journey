{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bcc7ed5",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "Neural networks are a class of machine learning models inspired by the human brain. They are composed of layers of interconnected nodes (neurons) and are capable of learning complex patterns from data.\n",
    "\n",
    "## Key Concepts\n",
    "- **Neuron**: Basic unit that receives input, applies a function, and passes output.\n",
    "- **Layer**: Group of neurons. Types include input, hidden, and output layers.\n",
    "- **Activation Function**: Introduces non-linearity (e.g., ReLU, sigmoid).\n",
    "- **Loss Function**: Measures prediction error.\n",
    "- **Backpropagation**: Algorithm for training neural networks by updating weights.\n",
    "\n",
    "Let's build and train a simple neural network using Python and Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002ea4c9",
   "metadata": {},
   "source": [
    "## Simple Neural Network for Classification\n",
    "\n",
    "We'll use the Keras library (part of TensorFlow) to build a neural network for classifying points in the Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80df8f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TensorFlow if not already installed\n",
    "# !pip install tensorflow\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Load and preprocess data\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target.reshape(-1, 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(8, activation='relu', input_shape=(4,)),\n",
    "    keras.layers.Dense(8, activation='relu'),\n",
    "    keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=8, validation_split=0.1, verbose=0)\n",
    "\n",
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57058eb2",
   "metadata": {},
   "source": [
    "## Visualizing Training History\n",
    "\n",
    "Let's plot the training and validation accuracy over epochs to see how the model learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b12e225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training History')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e2d744",
   "metadata": {},
   "source": [
    "## Types of Neural Networks\n",
    "\n",
    "- **Feedforward Neural Networks (FNN)**: \n",
    "  - The simplest type of neural network. Information flows in one direction, from input to output, without cycles or loops. Used for basic classification and regression tasks.\n",
    "\n",
    "- **Convolutional Neural Networks (CNN)**: \n",
    "  - Designed to process grid-like data such as images. They use convolutional layers to automatically learn spatial hierarchies of features. Widely used in computer vision tasks like image classification, object detection, and facial recognition.\n",
    "\n",
    "- **Recurrent Neural Networks (RNN)**: \n",
    "  - Specialized for sequential data, such as time series, speech, or text. RNNs have connections that form cycles, allowing information to persist. Variants like LSTM (Long Short-Term Memory) and GRU (Gated Recurrent Unit) help capture long-term dependencies. Used in language modeling, translation, and sequence prediction.\n",
    "\n",
    "- **Generative Adversarial Networks (GANs)**: \n",
    "  - Consist of two networks: a generator and a discriminator. The generator creates new data samples, while the discriminator evaluates them. They compete in a game-theoretic setup, leading to the generation of realistic data. Used for image synthesis, data augmentation, and creative applications.\n",
    "\n",
    "- **Autoencoders**: \n",
    "  - Unsupervised neural networks that learn to compress (encode) data into a lower-dimensional representation and then reconstruct (decode) it back. Useful for dimensionality reduction, denoising, and anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19731127",
   "metadata": {},
   "source": [
    "### Feedforward Neural Network Example\n",
    "A simple dense network for classification (already shown above).\n",
    "\n",
    "### Convolutional Neural Network (CNN) Example\n",
    "Below is a minimal CNN for image classification using Keras and the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c79344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Example: MNIST Digit Classification\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Load data\n",
    "def load_mnist():\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    X_train = X_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "    X_test = X_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "    y_train = to_categorical(y_train, 10)\n",
    "    y_test = to_categorical(y_test, 10)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_mnist()\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train[:10000], y_train[:10000], epochs=2, batch_size=128, verbose=0)  # Use subset for speed\n",
    "loss, acc = model.evaluate(X_test[:2000], y_test[:2000], verbose=0)\n",
    "print(f\"CNN test accuracy (subset): {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f4f119",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network (RNN) Example\n",
    "A minimal RNN for sequence prediction using Keras and synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aabf23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN Example: Sequence Prediction\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "\n",
    "# Generate synthetic sequential data\n",
    "X_seq = np.random.rand(100, 10, 1)\n",
    "y_seq = np.random.randint(0, 2, 100)\n",
    "\n",
    "model = Sequential([\n",
    "    SimpleRNN(8, activation='tanh', input_shape=(10, 1)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_seq, y_seq, epochs=5, batch_size=8, verbose=0)\n",
    "loss, acc = model.evaluate(X_seq, y_seq, verbose=0)\n",
    "print(f\"RNN accuracy (synthetic): {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611e67ae",
   "metadata": {},
   "source": [
    "### Generative Adversarial Network (GAN) Example\n",
    "A minimal GAN structure for generating synthetic data (training omitted for brevity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96703a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN Example: Minimal Structure\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "def build_generator():\n",
    "    model = Sequential([\n",
    "        Dense(16, input_dim=10),\n",
    "        LeakyReLU(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_discriminator():\n",
    "    model = Sequential([\n",
    "        Dense(16, input_dim=1),\n",
    "        LeakyReLU(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "print(\"Generator and Discriminator models created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f0c5a0",
   "metadata": {},
   "source": [
    "### Autoencoder Example\n",
    "A simple autoencoder for dimensionality reduction using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc74c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder Example: Dimensionality Reduction\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Synthetic data\n",
    "data = np.random.rand(100, 20)\n",
    "\n",
    "# Encoder\n",
    "input_layer = Input(shape=(20,))\n",
    "encoded = Dense(8, activation='relu')(input_layer)\n",
    "# Decoder\n",
    "decoded = Dense(20, activation='sigmoid')(encoded)\n",
    "\n",
    "# Autoencoder model\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.fit(data, data, epochs=10, batch_size=8, verbose=0)\n",
    "encoded_data = Model(input_layer, encoded).predict(data)\n",
    "print(f\"Encoded data shape: {encoded_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d41db4",
   "metadata": {},
   "source": [
    "# CNN - Convolutional Neural Network\n",
    "Convolutional Neural Networks (CNNs) are specialized neural networks designed for processing grid-like data such as images. They use convolutional layers to automatically and adaptively learn spatial hierarchies of features.\n",
    "\n",
    "**Key Components:**\n",
    "- **Convolutional Layer:** Applies filters to extract features from input data.\n",
    "- **Pooling Layer:** Reduces spatial dimensions, helping with overfitting and computation.\n",
    "- **Flatten Layer:** Converts 2D feature maps to 1D for the dense layer.\n",
    "- **Dense Layer:** Fully connected layer for classification.\n",
    "\n",
    "Below is an example of building a simple CNN for image classification using Keras and the MNIST dataset.\n",
    "You can visualize the training history similarly to the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a3cd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load and preprocess data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Build CNN model\n",
    "cnn_model = keras.Sequential([\n",
    "    keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "cnn_history = cnn_model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.1, verbose=0)\n",
    "\n",
    "# Evaluate model\n",
    "cnn_loss, cnn_accuracy = cnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test accuracy (CNN): {cnn_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff98d23",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Neural networks are powerful models for learning complex patterns.\n",
    "- There are various types of neural networks, each suited for different tasks (FNN, CNN, RNN, GAN, Autoencoder, etc.).\n",
    "- We built a simple neural network for classification using Keras.\n",
    "- Training history visualization helps understand model learning.\n",
    "\n",
    "Try experimenting with more layers, different architectures, or other datasets!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
