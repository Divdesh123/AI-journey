{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd11262",
   "metadata": {},
   "source": [
    "#### Feature Store\n",
    "A feature store is a centralized repository for storing, sharing, and managing features used in machine learning models. It helps ensure consistency between training and serving, supports feature reuse, and enables real-time feature access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8b7241",
   "metadata": {},
   "source": [
    "#### Offline vs. Online Inference\n",
    "- **Offline inference**: Predictions are made in batches, often on a schedule, and results are stored for later use (e.g., nightly churn prediction).\n",
    "- **Online inference**: Predictions are made in real-time as requests arrive, enabling immediate responses (e.g., fraud detection during a transaction)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ec6040",
   "metadata": {},
   "source": [
    "#### Batch vs. Real-Time Pipelines\n",
    "- **Batch pipelines**: Process large volumes of data at once, suitable for periodic updates and analytics.\n",
    "- **Real-time pipelines**: Process data as it arrives, enabling immediate actions and up-to-date insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd940dbd",
   "metadata": {},
   "source": [
    "#### Model Monitoring & Drift\n",
    "Model monitoring tracks the performance of deployed models over time. Drift occurs when the data or relationships change, causing model accuracy to degrade. Monitoring helps detect drift and trigger retraining or updates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404c1cba",
   "metadata": {},
   "source": [
    "#### End-to-End ML Pipeline Design\n",
    "A typical ML pipeline includes:\n",
    "1. **Data Collection**: Gather raw data from various sources.\n",
    "2. **Data Processing**: Clean, transform, and engineer features.\n",
    "3. **Model Training**: Train models using processed data.\n",
    "4. **Model Evaluation**: Assess model performance.\n",
    "5. **Deployment**: Serve the model for inference.\n",
    "6. **Monitoring**: Track model performance and data drift.\n",
    "\n",
    "Let's see a basic code example for a simple ML pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e7549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic ML Pipeline Example\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Data Collection\n",
    "# (Here, we create synthetic data)\n",
    "data = pd.DataFrame({\n",
    "    'feature1': np.random.rand(100),\n",
    "    'feature2': np.random.rand(100),\n",
    "    'label': np.random.randint(0, 2, 100)\n",
    "})\n",
    "\n",
    "# 2. Data Processing\n",
    "X = data[['feature1', 'feature2']]\n",
    "y = data['label']\n",
    "\n",
    "# 3. Model Training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Model Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
